{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Data, Train, Test, and Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score,  classification_report\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "seed = 83 # last 2 digits of student number\n",
    "training_size = 0.7\n",
    "testing_size = (1 - training_size) / 2 # 0.15\n",
    "validation_size = testing_size # 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ax        ay        az        gx        gy        gz  label\n",
      "0    0.993808 -0.097925  0.118973  0.040237  0.035752  0.004211      0\n",
      "1    0.988688 -0.109838  0.136743  0.816688  0.007225  0.168807      0\n",
      "2    1.001085 -0.055752  0.089284 -0.110351  0.044556 -0.029301      0\n",
      "3    0.989726 -0.084137  0.099642 -0.198425  0.027685 -0.084684      0\n",
      "4    0.995308 -0.050707  0.118655 -0.134315  0.041383 -0.045558      0\n",
      "..        ...       ...       ...       ...       ...       ...    ...\n",
      "251  1.022338  0.005755  0.037175  2.002824  0.141620  0.257420      3\n",
      "252  1.003883  0.002298  0.087594  1.765348  0.106364  0.286881      3\n",
      "253  1.006630  0.008186  0.062279  1.715213  0.078407  0.191578      3\n",
      "254  1.006600  0.058155  0.031343  1.790672  0.119087  0.160586      3\n",
      "255  1.004353  0.046171  0.025106  1.858132  0.119590  0.116498      3\n",
      "\n",
      "[256 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load all the data\n",
    "DATA_PATH = \"raw_data\"\n",
    "acceleration_x = pd.read_csv(os.path.join(DATA_PATH, \"acceleration_x.csv\"))\n",
    "acceleration_y = pd.read_csv(os.path.join(DATA_PATH, \"acceleration_y.csv\"))\n",
    "acceleration_z = pd.read_csv(os.path.join(DATA_PATH, \"acceleration_z.csv\"))\n",
    "gyroscope_x = pd.read_csv(os.path.join(DATA_PATH, \"gyroscope_x.csv\"))\n",
    "gyroscope_y = pd.read_csv(os.path.join(DATA_PATH, \"gyroscope_y.csv\"))\n",
    "gyroscope_z = pd.read_csv(os.path.join(DATA_PATH, \"gyroscope_z.csv\"))\n",
    "labels = pd.read_csv(os.path.join(DATA_PATH, \"labels.csv\"))\n",
    "\n",
    "# get the mean of each data point\n",
    "df = pd.DataFrame({\n",
    "    \"ax\": acceleration_x.mean(axis=1),\n",
    "    \"ay\": acceleration_y.mean(axis=1),\n",
    "    \"az\": acceleration_z.mean(axis=1),\n",
    "    \"gx\": gyroscope_x.mean(axis=1),\n",
    "    \"gy\": gyroscope_y.mean(axis=1),\n",
    "    \"gz\": gyroscope_z.mean(axis=1),\n",
    "    \"label\": labels.iloc[:, 0]  # first column of labels\n",
    "})\n",
    "\n",
    "\n",
    "print(df)  # preview first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ax        ay        az        gx        gy        gz  label  \\\n",
      "0    0.993808 -0.097925  0.118973  0.040237  0.035752  0.004211      0   \n",
      "1    0.988688 -0.109838  0.136743  0.816688  0.007225  0.168807      0   \n",
      "2    1.001085 -0.055752  0.089284 -0.110351  0.044556 -0.029301      0   \n",
      "3    0.989726 -0.084137  0.099642 -0.198425  0.027685 -0.084684      0   \n",
      "4    0.995308 -0.050707  0.118655 -0.134315  0.041383 -0.045558      0   \n",
      "..        ...       ...       ...       ...       ...       ...    ...   \n",
      "251  1.022338  0.005755  0.037175  2.002824  0.141620  0.257420      3   \n",
      "252  1.003883  0.002298  0.087594  1.765348  0.106364  0.286881      3   \n",
      "253  1.006630  0.008186  0.062279  1.715213  0.078407  0.191578      3   \n",
      "254  1.006600  0.058155  0.031343  1.790672  0.119087  0.160586      3   \n",
      "255  1.004353  0.046171  0.025106  1.858132  0.119590  0.116498      3   \n",
      "\n",
      "        g_mag  \n",
      "0    0.053990  \n",
      "1    0.833983  \n",
      "2    0.122561  \n",
      "3    0.217509  \n",
      "4    0.147745  \n",
      "..        ...  \n",
      "251  2.024259  \n",
      "252  1.791666  \n",
      "253  1.727659  \n",
      "254  1.801797  \n",
      "255  1.865618  \n",
      "\n",
      "[256 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# calcualte gyroscope magnitude (engineered feature)\n",
    "df[\"g_mag\"] = np.sqrt(df[\"gx\"]**2 + df[\"gy\"]**2 + df[\"gz\"]**2)\n",
    "print(df)  # preview first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Test, Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X = df.drop(columns=[\"label\"])\n",
    "y = df[\"label\"]\n",
    "\n",
    "# gets us 70 / 15 / 15 for train/test/validation\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=testing_size,\n",
    "    random_state=seed,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "val_ratio = 0.15 / 0.85  # â‰ˆ 0.17647\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val,\n",
    "    test_size=val_ratio,\n",
    "    random_state=seed,\n",
    "    stratify=y_train_val\n",
    ")\n",
    "\n",
    "\n",
    "# Save X_train\n",
    "pd.DataFrame(X_train).to_csv(\"X_train.csv\", index=False)\n",
    "\n",
    "# Save X_test\n",
    "pd.DataFrame(X_test).to_csv(\"X_test.csv\", index=False)\n",
    "\n",
    "# Save y_train\n",
    "pd.DataFrame(y_train, columns=[\"label\"]).to_csv(\"y_train.csv\", index=False)\n",
    "\n",
    "# Save y_test\n",
    "pd.DataFrame(y_test, columns=[\"label\"]).to_csv(\"y_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 7)\n",
      "(39, 7)\n",
      "(39, 7)\n"
     ]
    }
   ],
   "source": [
    "# scale data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = SVC(kernel='linear', C=1, random_state=seed)\n",
    "svm_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Save the model\n",
    "with open(\"svm_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(svm_classifier, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Validation ==========\n",
      "Accuracy: 1.00\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       1.00      1.00      1.00        10\n",
      "           2       1.00      1.00      1.00        10\n",
      "           3       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        39\n",
      "   macro avg       1.00      1.00      1.00        39\n",
      "weighted avg       1.00      1.00      1.00        39\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 9  0  0  0]\n",
      " [ 0 10  0  0]\n",
      " [ 0  0 10  0]\n",
      " [ 0  0  0 10]] \n",
      "\n",
      "========== Training ==========\n",
      "Accuracy: 1.00\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       1.00      1.00      1.00        43\n",
      "           2       1.00      1.00      1.00        48\n",
      "           3       1.00      1.00      1.00        44\n",
      "\n",
      "    accuracy                           1.00       178\n",
      "   macro avg       1.00      1.00      1.00       178\n",
      "weighted avg       1.00      1.00      1.00       178\n",
      "\n",
      "Confusion Matrix:\n",
      "[[43  0  0  0]\n",
      " [ 0 43  0  0]\n",
      " [ 0  0 48  0]\n",
      " [ 0  0  0 44]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def display_results(ground_truth, prediction, title):\n",
    "    print(f\"========== {title} ==========\")\n",
    "    print(f\"Accuracy: {accuracy_score(ground_truth, prediction):.2f}\\n\")\n",
    "    print(classification_report(ground_truth, prediction))\n",
    "\n",
    "    cm = confusion_matrix(ground_truth, prediction)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm, \"\\n\")\n",
    "\n",
    "y_pred_val = svm_classifier.predict(X_val_scaled)\n",
    "y_pred_train = svm_classifier.predict(X_train_scaled)\n",
    "\n",
    "\n",
    "display_results(y_val, y_pred_val, \"Validation\")\n",
    "display_results(y_train, y_pred_train, \"Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Testing ==========\n",
      "Accuracy: 1.00\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        10\n",
      "           3       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        39\n",
      "   macro avg       1.00      1.00      1.00        39\n",
      "weighted avg       1.00      1.00      1.00        39\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10  0  0  0]\n",
      " [ 0  9  0  0]\n",
      " [ 0  0 10  0]\n",
      " [ 0  0  0 10]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = svm_classifier.predict(X_test_scaled)\n",
    "\n",
    "display_results(y_test, y_pred_test, \"Testing\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
